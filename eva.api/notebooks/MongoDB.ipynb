{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PARENT_PATH = Path.cwd().parent\n",
    "OUTPUT_PATH = PARENT_PATH / 'data' / 'processed' / 'pmdg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "MONGO_URI = os.environ[\"MONGO_URI\"]\n",
    "DB_NAME = \"GAIA\"\n",
    "COLLECTION_NAME = \"PMDG\"\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\"\n",
    "\n",
    "\n",
    "EMBEDDING_FIELD_NAME = \"embedding\"\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "collection = db[COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "\n",
    "docs = [10]\n",
    "for i in docs:\n",
    "    loader = TextLoader(OUTPUT_PATH / (str(i) + '.txt'))\n",
    "    documents = loader.load()\n",
    "\n",
    "    #print(documents)\n",
    "    #text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    #docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    #documents[0].metadata = { 'source':\"1234\" }\n",
    "\n",
    "    # insert the documents in MongoDB Atlas Vector Search\n",
    "    x = MongoDBAtlasVectorSearch.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=OpenAIEmbeddings(disallowed_special=()),\n",
    "        collection=collection, \n",
    "        index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "\n",
    "vector_search = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "   MONGO_URI,\n",
    "   DB_NAME + \".\" + COLLECTION_NAME,\n",
    "   OpenAIEmbeddings(disallowed_special=()),\n",
    "   index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME\n",
    ")\n",
    "query = \"Ageratum conyzoides\"\n",
    "results = vector_search.similarity_search(\n",
    "   query=query,\n",
    "   k=20,\n",
    ")\n",
    "\n",
    "print(results)\n",
    "\n",
    "for result in results:\n",
    "   print( result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "qa_retriever = vector_search.as_retriever(\n",
    "   search_type=\"similarity\",\n",
    "   search_kwargs={\n",
    "       \"k\": 5,\n",
    "       \"post_filter_pipeline\": [{\"$limit\": 25}]\n",
    "   }\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "   template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(),chain_type=\"stuff\", retriever=qa_retriever, return_source_documents=True, chain_type_kwargs={\"prompt\": PROMPT})\n",
    "docs = qa({\"query\": \"Suggest biocontrols if my rice crop suffers from Meloidogyne graminicola\"})\n",
    "\n",
    "\n",
    "print(docs[\"result\"])\n",
    "print(docs['source_documents'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
